global:
  default_inherits: default

tools:
  default:
    cores: 1
    mem: cores * 3.8
    env: {}
    context:
      partition: main
      test_cores: 1  # TODO: test_mem?
      max_concurrent_job_count_for_tool_total: null
      max_concurrent_job_count_for_tool_user: null
    scheduling:
      reject:
        - offline
    rules:
    - id: max_concurrent_job_count_for_tool_rule
      if: |
        total_limit_exceeded = False
        user_limit_exceeded = False
        if max_concurrent_job_count_for_tool_total:
          total_limit_exceeded = helpers.concurrent_job_count_for_tool(app, tool) >= max_concurrent_job_count_for_tool_total
        if max_concurrent_job_count_for_tool_user and not total_limit_exceeded:
          user_limit_exceeded = helpers.concurrent_job_count_for_tool(app, tool, user) >= max_concurrent_job_count_for_tool_user
        total_limit_exceeded or user_limit_exceeded
      execute: |
        from galaxy.jobs.mapper import JobNotReadyException
        raise JobNotReadyException()
    rank: |  # TODO: rank function needs overhaul to consider memory
      import requests
      import random
      grafana_destinations = {  # dict of destinations where the key from the stats api call differs from the destination id
        'Galaxy-Main': 'slurm',
        'pulsar-high-mem-1': 'pulsar-high-mem1',
        'pulsar-qld-himem-0': 'pulsar-qld-high-mem0',
        'pulsar-qld-himem-1': 'pulsar-qld-high-mem1',
        'pulsar-qld-himem-2': 'pulsar-qld-high-mem2',
      }
      params = {
        'pretty': 'true',
        'db': 'queues',
        'q': 'SELECT last("percent_allocated") from "sinfo" group by "host"'
      }
      if len(candidate_destinations) > 1:
        try:
          response = requests.get('https://stats.usegalaxy.org.au:8086/query', auth=('grafana', '{{ vault_influx_grafana_password }}'), params=params)
          data = response.json()
          cpu_by_destination = {grafana_destinations.get(s['tags']['host'], s['tags']['host']):s['values'][0][1] for s in data.get('results')[0].get('series', [])}
          # sort by cpu usage
          candidate_destinations.sort(key=lambda d: (cpu_by_destination.get(d.id), random.randint(0,9)))
          final_destinations = candidate_destinations
        except Exception:
          log.exception("An error occurred while querying influxdb. Using a weighted random candidate destination")
          final_destinations = helpers.weighted_random_sampling(candidate_destinations)
      else:
        final_destinations = candidate_destinations
      final_destinations
